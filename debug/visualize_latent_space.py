"""
Connectorå±¤ã®å‡ºåŠ›ã¨æ­£è§£æ–‡å­—åˆ—ã®LLM embeddingsã®æ½œåœ¨ç©ºé–“åˆ†å¸ƒã‚’å¯è¦–åŒ–
"""
import sys
import os

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ ï¼ˆmodelsã¨utilsã‚’importã™ã‚‹ãŸã‚ï¼‰
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
from omegaconf import OmegaConf
from models import HTRNet
from utils.htr_dataset import HTRDataset
import random
import matplotlib.pyplot as plt
import numpy as np
from sklearn.manifold import TSNE
import torch.nn.functional as F
from datetime import datetime

# results/æ—¥ä»˜-æ™‚åˆ»/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆè¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ï¼‰
timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')
results_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'results', timestamp)
os.makedirs(results_dir, exist_ok=True)
print(f"ğŸ“ Created/verified results directory: {results_dir}")

# è¨­å®šãƒ­ãƒ¼ãƒ‰ï¼ˆè¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ï¼‰
config_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'config.yaml')
config = OmegaConf.load(config_path)

device = torch.device(config.device if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
print("\nğŸ“‚ Loading dataset...")

# config.data.pathã®ç›¸å¯¾ãƒ‘ã‚¹ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰è§£æ±º
data_path = config.data.path
if not os.path.isabs(data_path):
    # config.yamlãŒã‚ã‚‹è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆï¼‰ã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    data_path = os.path.join(project_root, data_path)

dataset = HTRDataset(
    data_path,
    'test',
    fixed_size=(config.preproc.image_height, config.preproc.image_width)
)

# å­¦ç¿’æ™‚ã®æ–‡å­—ã‚¯ãƒ©ã‚¹ã‚’èª­ã¿è¾¼ã¿ï¼ˆsaved_models/classes.npyã‹ã‚‰ï¼‰
classes_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
                           'saved_models', 'classes.npy')
classes = np.load(classes_path, allow_pickle=True).tolist()
print(f"Character classes: {len(classes)} different characters (loaded from training)")

# ãƒ¢ãƒ‡ãƒ«ä½œæˆï¼ˆLLMæœ‰åŠ¹ï¼‰
print("\nğŸ”§ Creating model with LLM enabled...")
net = HTRNet(config.arch, len(classes) + 1, use_llm=True)

# å­¦ç¿’æ¸ˆã¿é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆè¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ï¼‰
model_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
                          'saved_models', '10-30_llmmobilevit', '100.pt')
print(f"\nğŸ“¥ Loading checkpoint: {model_path}")
load_dict = torch.load(model_path, map_location='cpu')
missing_keys, unexpected_keys = net.load_state_dict(load_dict, strict=True)

print(f"âœ… Loaded checkpoint successfully")

if missing_keys:
    print(f"   Missing keys: {len(missing_keys)}")
if unexpected_keys:
    print(f"   Unexpected keys: {len(unexpected_keys)}")

net.to(device)
net.eval()

# ã‚µãƒ³ãƒ—ãƒ«é¸æŠ
print("\nğŸ” Analyzing latent space distribution...\n")
print("="*80)

num_samples = 5
indices = [5,37,12,4,67]  # å›ºå®šã‚µãƒ³ãƒ—ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

for i, idx in enumerate(indices):
    img, transcr = dataset[idx]
    img = img.unsqueeze(0).to(device)

    print(f"\n{'='*80}")
    print(f"Sample {i+1}/{num_samples} (Index: {idx})")
    print(f"{'='*80}")
    print(f"ğŸ“ Ground Truth: '{transcr}'")

    with torch.no_grad():
        # 1. ç‰¹å¾´é‡æŠ½å‡º
        if net.stn is not None:
            img_feat = net.stn(img)
        else:
            img_feat = img
        y = net.features(img_feat)

        # 2. RNN layer1å‡ºåŠ›å–å¾—
        y_seq = y.permute(2, 3, 0, 1)[0]
        y1 = net.top.rec1(y_seq)[0]

        # 3. Connectorå‡ºåŠ›å–å¾— (128, 3072)
        prefix_input = y1.permute(1, 0, 2)
        connector_output = net.top.connector(prefix_input).squeeze(0)  # (128, 3072)

        # 4. æ­£è§£æ–‡å­—åˆ—ã®LLM embeddingså–å¾— (seq_len, 3072)
        tokens = net.top.llm.tokenizer(
            [transcr],  # ãƒªã‚¹ãƒˆã§ãƒ©ãƒƒãƒ—
            return_tensors="pt",
            padding=False,  # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãªã—ï¼ˆå®Ÿéš›ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å–å¾—ï¼‰
            truncation=False  # åˆ‡ã‚Šè©°ã‚ãªã—
        )
        token_ids = tokens.input_ids.to(device)
        gt_embeddings = net.top.llm.model.model.embed_tokens(token_ids).squeeze(0)  # (seq_len, 3072)

        print(f"ğŸ”§ Connector output shape: {connector_output.shape}")
        print(f"ğŸ”§ GT embeddings shape: {gt_embeddings.shape}")

        # === å¯è¦–åŒ–1: t-SNEæ•£å¸ƒå›³ ===
        print("ğŸ“Š Generating t-SNE visualization...")
        all_vectors = torch.cat([connector_output, gt_embeddings], dim=0).cpu().numpy()

        # t-SNEã§2æ¬¡å…ƒã«å‰Šæ¸›
        tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(all_vectors)-1))
        reduced = tsne.fit_transform(all_vectors)

        num_connector_tokens = connector_output.shape[0]
        connector_2d = reduced[:num_connector_tokens]
        gt_2d = reduced[num_connector_tokens:]

        # ãƒ—ãƒ­ãƒƒãƒˆ
        plt.figure(figsize=(12, 8))
        plt.scatter(connector_2d[:, 0], connector_2d[:, 1],
                   c='blue', marker='o', s=50, alpha=0.6, label=f'Connector output ({num_connector_tokens} tokens)')
        plt.scatter(gt_2d[:, 0], gt_2d[:, 1],
                   c='red', marker='x', s=100, alpha=0.8, label=f'GT embeddings ({len(gt_2d)} tokens)')
        plt.legend(fontsize=12)
        plt.title(f"Latent Space Distribution (t-SNE)\nGT: '{transcr}'", fontsize=14)
        plt.xlabel('t-SNE dimension 1', fontsize=12)
        plt.ylabel('t-SNE dimension 2', fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(results_dir, f'latent_space_sample_{i+1}.png'), dpi=150, bbox_inches='tight')
        plt.close()

        # === å¯è¦–åŒ–2: ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— ===
        print("ğŸ“Š Generating cosine similarity heatmap...")
        similarity = F.cosine_similarity(
            connector_output.unsqueeze(1),  # (128, 1, 3072)
            gt_embeddings.unsqueeze(0),     # (1, seq_len, 3072)
            dim=2  # (128, seq_len)
        ).cpu().numpy()

        plt.figure(figsize=(max(10, len(gt_embeddings)), 10))
        im = plt.imshow(similarity, cmap='viridis', aspect='auto')
        plt.colorbar(im, label='Cosine Similarity')
        plt.xlabel(f'GT tokens ({len(gt_embeddings)})', fontsize=12)
        plt.ylabel('Connector tokens (128)', fontsize=12)
        plt.title(f"Cosine Similarity Heatmap\nGT: '{transcr}'", fontsize=14)

        # çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
        mean_sim = similarity.mean()
        max_sim = similarity.max()
        min_sim = similarity.min()
        plt.text(0.02, 0.98, f'Mean: {mean_sim:.3f}\nMax: {max_sim:.3f}\nMin: {min_sim:.3f}',
                transform=plt.gca().transAxes, fontsize=10, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

        plt.tight_layout()
        plt.savefig(os.path.join(results_dir, f'similarity_heatmap_{i+1}.png'), dpi=150, bbox_inches='tight')
        plt.close()

        # === å¯è¦–åŒ–3: ãƒãƒ«ãƒ åˆ†å¸ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ  ===
        print("ğŸ“Š Generating norm distribution histogram...")
        connector_norms = torch.norm(connector_output, dim=1).cpu().numpy()
        gt_norms = torch.norm(gt_embeddings, dim=1).cpu().numpy()

        plt.figure(figsize=(12, 6))
        plt.hist(connector_norms, bins=30, alpha=0.6, label='Connector output', color='blue', edgecolor='black')
        plt.hist(gt_norms, bins=30, alpha=0.6, label='GT embeddings', color='red', edgecolor='black')
        plt.axvline(connector_norms.mean(), color='blue', linestyle='--', linewidth=2,
                   label=f'Connector mean: {connector_norms.mean():.2f}')
        plt.axvline(gt_norms.mean(), color='red', linestyle='--', linewidth=2,
                   label=f'GT mean: {gt_norms.mean():.2f}')
        plt.xlabel('L2 Norm', fontsize=12)
        plt.ylabel('Frequency', fontsize=12)
        plt.legend(fontsize=11)
        plt.title(f'Distribution of Vector Norms\nGT: \'{transcr}\'', fontsize=14)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(results_dir, f'norm_distribution_{i+1}.png'), dpi=150, bbox_inches='tight')
        plt.close()

        print(f"âœ… Saved visualizations to {results_dir}")
        print(f"   - latent_space_sample_{i+1}.png")
        print(f"   - similarity_heatmap_{i+1}.png")
        print(f"   - norm_distribution_{i+1}.png")

print(f"\n{'='*80}")
print("âœ… All visualizations complete!")
print(f"ğŸ“Š Total files created: {num_samples * 3} images")
print(f"ğŸ“‚ Output directory: {results_dir}")
print(f"{'='*80}")

print("\nğŸ’¡ Note:")
print("   - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆ700 epoch, LLMè¾¼ã¿ï¼‰ã‚’ä½¿ç”¨")
print("   - é’è‰²: Connectorå‡ºåŠ› (å¯å¤‰é•·ãƒˆãƒ¼ã‚¯ãƒ³, 3072æ¬¡å…ƒ)")
print("   - èµ¤è‰²: æ­£è§£embeddings (å¯å¤‰é•·, 3072æ¬¡å…ƒ)")
print("   - t-SNEã§æ½œåœ¨ç©ºé–“ã®åˆ†å¸ƒã‚’å¯è¦–åŒ–")
print("   - ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§ä¸¡è€…ã®å¯¾å¿œé–¢ä¿‚ã‚’åˆ†æ")
print("   - å­¦ç¿’ãŒé€²ã‚“ã§ã„ã‚‹å ´åˆã€é’ã¨èµ¤ãŒè¿‘ã¥ã„ã¦ã„ã‚‹ã¯ãš")
