resume: ./saved_models/CRNN+LLM/700.pt
save: './temp.pt'

device: 'cuda:0'

# datasets
data:
  path: './data/IAM/processed_lines'

# preprocessing
preproc:
  image_height: 128
  image_width: 1024

# architecture
arch:
  cnn_cfg: [[2, 64], 'M', "mobilevit1", [4, 128], 'M' ,"mobilevit2", [4, 256]]
  head_type: 'both'  # select from 'both' (rnn + cnn shortcut), 'rnn', 'cnn'
  rnn_type: 'lstm'
  rnn_layers: 3
  rnn_hidden_size: 256
  flattening: 'maxpool'
  stn: False

# training
train:
  lr: 1e-3
  num_epochs: 800
  batch_size: 8  # Reduced from 32 to prevent OOM
  scheduler: 'mstep'  # right now only 'mstep' is supported, i.e. multistep
  save_every_k_epochs: 50
  num_workers: 3
  use_llm: true  # Enable LLM-based learning (true/false)
  llm_sample_ratio: 0.0625  # 1/16 of samples per batch use LLM (only when use_llm=true)
  accumulation_steps: 4  # Accumulate gradients over 4 steps to maintain effective batch size of 32
  llm_source: 'all'  # 'rnn', 'mobilevit1', 'mobilevit2', 'rnn+mobilevit1', 'rnn+mobilevit2', 'mobilevit1+mobilevit2', 'all'
  llm_loss_weights:
    rnn: 1.0         # RNN経路のLLM損失の重み
    mobilevit1: 0.5  # MobileViT1経路のLLM損失の重み
    mobilevit2: 0.5  # MobileViT2経路のLLM損失の重み

# evaluation
eval:
  batch_size: 8  # Reduced from 32 to prevent OOM during evaluation
  num_workers: 8
  wer_mode: 'tokenizer' # select from 'tokenizer', 'space'


# model saving and logging
model:
  save_dir: './saved_models/11-04_llmmobilevit'
